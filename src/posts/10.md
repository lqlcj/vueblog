---
title: "🔗 视觉编程的魅力：ComfyUI 用法深度指南与工作流构建艺术"
date: 2025-5-20
cover: "/images/10.jpg"
ratio: 0.75
---
如果你已经厌倦了传统 Stable Diffusion 界面中那些层层叠叠的下拉菜单和参数设置，那么是时候拥抱 ComfyUI 的世界了！ComfyUI 彻底颠覆了我们与 AI 图像生成工具的交互方式。它不是一个简单的 WebUI，而是一个基于节点（Node）和流程图（Workflow）的强大工具，让你以视觉编程的方式，像搭积木一样，精确地控制 AI 模型的每一个步骤。

本文将作为你的 ComfyUI 入门指南，从核心概念到进阶应用，带你领略这种流程化、透明化 AI 图像生成的新艺术。🎨

1. ComfyUI 的核心理念：一切皆为节点 💡
与传统的 SD WebUI 将所有功能（加载模型、输入提示词、采样器选择）集成在一个面板中不同，ComfyUI 将整个图像生成过程彻底模块化：

节点 (Node)：图中的每一个小方块就是一个节点，它代表了图像生成过程中的一个独立功能，例如 Load Checkpoint（加载模型）、CLIP Text Encode（文本编码）、KSampler（采样器）等。

连接 (Connection)：节点之间的连线代表了数据流。数据（如模型权重、文本特征、潜在空间图像）从一个节点的输出端口流向另一个节点的输入端口。

工作流 (Workflow)：整个连接起来的流程图就是一个完整的工作流。

这种模块化最大的好处是透明度高和高度可定制。你可以清楚地看到数据在每一步是如何被处理和转换的。

2. ComfyUI 基础用法：构建你的第一个工作流 🛠️
一个标准的 ComfyUI 图像生成工作流通常包含以下几个核心步骤：

步骤一：加载与配置模型 💾
这是流程的起点，你需要告诉 AI 你要使用哪个“大脑”。

Load Checkpoint 节点：拖入或搜索该节点，选择你的主模型（Checkpoint）。它通常有三个输出端口：MODEL（模型）、CLIP（文本编码器）、VAE（变分自编码器）。

CLIP Text Encode 节点：拖入两个该节点，一个用于正向提示词（Prompt），一个用于反向提示词（Negative Prompt）。

将 Load Checkpoint 的 CLIP 端口连接到这两个节点的 CLIP 输入。

在节点的大文本框中分别输入你的正向和反向提示词。

步骤二：核心采样：KSampler 的艺术 🔬
KSampler 是整个工作流的心脏，它负责将文本信息（CLIP 编码）转化为实际的图像。

KSampler 节点：将 Load Checkpoint 的 MODEL 连到 KSampler 的 model 输入。

连接编码：将正向提示词节点的输出连到 positive，反向提示词节点的输出连到 negative。

潜在空间图像 (Latent Image)：由于 KSampler 在潜在空间工作，你需要一个初始的随机噪声。

拖入 Empty Latent Image 节点：设置你想要的图像尺寸（如 512x512 或 1024x1024）。

将 Empty Latent Image 的输出连到 KSampler 的 latent_image 输入。

设置参数：在 KSampler 节点中，设置 seed（种子）、steps（步数）、cfg（提示词相关性）和 sampler / scheduler（采样方法和调度器）。

步骤三：解码与展示 🖼️
KSampler 的输出是一个潜在空间的压缩图像。我们需要 VAE 将其解码成可见的像素。

VAE Decode 节点：将 Load Checkpoint 的 VAE 端口连到 VAE Decode 的 vae 输入。

将 KSampler 的 LATENT 输出连到 VAE Decode 的 samples 输入。

Save Image 节点：将 VAE Decode 的 IMAGE 输出连到最终的 Save Image 或 Preview Image 节点，以便查看和保存结果。

3. ComfyUI 的进阶用法：模块化与重用 ⚙️
掌握了基础工作流后，ComfyUI 的真正魔力才开始展现：

A. 万能的 Reroute 节点
Reroute 节点（或称枢纽节点）本身不执行任何操作，但它对于整理工作流布局至关重要。

功能：你可以用它来分流数据到多个接收端，或者作为长距离连接的中转站，避免连线交错混乱。

技巧：在复杂的流程中，使用 Reroute 节点给关键数据线（如 MODEL 或 CLIP）一个统一的出口，能让整个图表更加清晰。

B. ControlNet 集成：精控姿态 🧍‍♀️
ControlNet 是 ComfyUI 的强项之一，因为它能完美地集成到工作流中，让你自由控制 ControlNet 应用的阶段。

加载 ControlNet 模型：拖入 Load ControlNet 节点。

前置处理器：拖入 Preprocessor 节点（如 OpenPose、Canny），将原始图像输入到这里。

集成到模型：使用 Apply ControlNet 节点。

将 Load Checkpoint 的 MODEL 端口和 Load ControlNet 的输出连接到 Apply ControlNet。

将 Preprocessor 的输出图像连接到 Apply ControlNet。

最后，将 Apply ControlNet 的 新 MODEL 输出，连接到 KSampler 的 model 输入。

C. 工作流的导入与导出 📤
ComfyUI 的一大优势是工作流的分享。

导入：你可以直接拖动任何一张用 ComfyUI 生成的 PNG 图片到你的 ComfyUI 界面中。如果原始图片包含了工作流元数据，它会自动加载并重建整个节点图！这是一个绝佳的学习和复现他人作品的方法。

导出：右键点击空白处，选择 Save Workflow 即可保存为 JSON 文件，供分享和备份。

4. 总结与效率魔法 ✨
ComfyUI 看起来复杂，但一旦你理解了“数据流”的概念，它的效率和控制力是无与伦比的：

性能优化：你可以精确控制哪些模型在哪些阶段被使用，甚至在复杂的流程中，只对需要修改的节点重新计算，而不是每次都从头运行。

无限扩展：通过安装自定义节点（Custom Nodes），ComfyUI 的功能几乎是无限的，你可以实现诸如高清修复 (Hires Fix)、Inpainting、批处理等所有 WebUI 具备，乃至更强大的功能。

入门建议：

从基础模板开始：不要试图从空白画布开始。先加载一个基础的工作流模板。

跟随数据线：在遇到问题时，沿着数据线从输入端 (Prompt) 一路追踪到输出端 (Save Image)，检查数据是否在每一步都正确地传递。

ComfyUI 是一个强大的、面向未来的 AI 图像生成界面。虽然初期学习曲线可能略陡峭，但它带来的透明度、精确控制和流程化思维，绝对值得每一位追求高品质 AI 图像创作者投入时间学习。开始你的节点之旅吧！🚀